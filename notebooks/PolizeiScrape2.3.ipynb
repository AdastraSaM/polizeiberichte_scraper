{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "pd.set_option(\"display.max_colwidth\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start = \"https://www.presseportal.de/blaulicht/nr/4970\"\n",
    "html = urlopen(Start)\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "Links=bs.find_all(\"h2\", class_=\"news-headline-clamp\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Pages not found again\n",
    "def getPagesNotfound(AllPagesNotfound):\n",
    "    \"\"\" Get all pages that threw an error\"\"\"\n",
    "    LinksNotFoundBefore=[]\n",
    "    LinksStillNotFOund=[]\n",
    "    for SinglePage in AllPagesNotfound:\n",
    "        try:\n",
    "            bs = BeautifulSoup(SinglePage, 'html.parser')\n",
    "            Tag=bs.find(class_=\"pagination-next\")\n",
    "            \n",
    "            LinksNotFoundBefore.append(\"https://www.presseportal.de\"+Tag.attrs['data-url'][1:])\n",
    "            time.sleep(.3)\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            LinksStillNotFOund.append(\"https://www.presseportal.de\"+Tag.attrs['data-url'][1:])\n",
    "    return LinksNotFoundBefore, LinksStillNotFOund\n",
    " \n",
    "    \n",
    "#getallsites\n",
    "Start = \"https://www.presseportal.de/blaulicht/nr/4970\"\n",
    "def getallsites(Start, MaxP):\n",
    "    \"\"\"Get the links of MaxP amount of subsequent sites that follow \"Start\" which contain the links to the individual news articles.\"\"\"\n",
    "    Pages=[]\n",
    "    PagesNotfound=[]\n",
    "    html = urlopen(Start)\n",
    "    Success =0\n",
    "    NoSuccess=0\n",
    "    for i in range(1,MaxP+1):\n",
    "        try:\n",
    "            bs = BeautifulSoup(html, 'html.parser')\n",
    "            Tag=bs.find(class_=\"pagination-next\")\n",
    "            Pages.append(\"https://www.presseportal.de\"+Tag.attrs['data-url'][1:])\n",
    "            html = urlopen(\"https://www.presseportal.de\"+Tag.attrs['data-url'][1:])\n",
    "            time.sleep(.3)\n",
    "            Success +=1\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            NoSuccess +=1\n",
    "            PagesNotfound.append(\"https://www.presseportal.de\"+Tag.attrs['data-url'][1:])\n",
    "        time.sleep(.3)\n",
    "        print(\"getallsites Progress \"+str(round(((i/MaxP)*100),2))+\"%\" + \" Success: \" +str(Success) + \" NoSuccess: \"+str(NoSuccess), flush=True,end='\\r')\n",
    "    LinksNotFoundBefore,LinksStillNotFOund = getPagesNotfound(PagesNotfound)\n",
    "    \n",
    "    for Link in LinksNotFoundBefore:\n",
    "        Pages.append(Link)\n",
    "    \n",
    "    return Pages,LinksStillNotFOund\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getallsites Progress 100.0% Success: 20 NoSuccess: 0\r"
     ]
    }
   ],
   "source": [
    "AllSites, SitesNotFound =getallsites(Start,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorpusFromLink(AllSites):\n",
    "    \"\"\"Get the corpus for each given link\"\"\"\n",
    "    MainsiteCorpus=[]\n",
    "    RemainingSites= []\n",
    "    for Site in AllSites:\n",
    "        try:\n",
    "            html = urlopen(Site)\n",
    "            bs = BeautifulSoup(html, 'html.parser')\n",
    "            Links=bs.find_all(\"h3\", class_=\"news-headline-clamp\" )\n",
    "            MainsiteCorpus.append(Links)\n",
    "        except:\n",
    "            RemainingSites.append(Site)\n",
    "            \n",
    "    return MainsiteCorpus, RemainingSites\n",
    "\n",
    "def getLinksFromCorpus(MainsiteCorpus):\n",
    "    \"\"\"ectract the link to each news for a given corpus\"\"\"\n",
    "    Linklist =[]\n",
    "    for Site in MainsiteCorpus:\n",
    "        for Headline in Site:\n",
    "            Article= (Headline.findChild(\"\")[\"href\"])\n",
    "            Linklist.append(Article)\n",
    "    return Linklist\n",
    "\n",
    "def findMainArticleForGivenText(Corpus):\n",
    "    \"\"\"find the main article for a given news-corpus\"\"\"\n",
    "    s = ''\n",
    "    for element in Corpus:\n",
    "        s += '\\n' + ''.join(element.findAll(text = True))\n",
    "        s\n",
    "    start = 'Polizeipräsidium Frankfurt am Main'\n",
    "    end = 'Rückfragen bitte an:'\n",
    "    s = (s[s.find(start)+len(start):s.rfind(end)])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewsFromLinks(Liste):\n",
    "    \"\"\"Return the Headline, Main Article, Link and the Pages not found for each given link\"\"\"\n",
    "    counter=0\n",
    "    counter2=0\n",
    "    News=[]\n",
    "    Headline=[]\n",
    "    Hauptartikel=[]\n",
    "    LinkNotfound=[]\n",
    "    for Link in Liste:\n",
    "        try:\n",
    "            html=urlopen('https://www.presseportal.de{}'.format(Link))\n",
    "            bs = BeautifulSoup(html, 'html.parser')\n",
    "            Ueberschrift= bs.find(\"h1\").get_text()\n",
    "            WholeText =bs.find_all('p')\n",
    "            MainArticle =findMainArticleForGivenText(WholeText)\n",
    "            Headline.append(Ueberschrift)\n",
    "            Hauptartikel.append(MainArticle)\n",
    "            counter+=1\n",
    "            News.append('https://www.presseportal.de{}'.format(Link))\n",
    "            time.sleep(.3)\n",
    "            print(\"found-> \"+ str(counter) + \"/\"+ str(counter2)+ \" of \"+ str(len(Liste)),flush=True,end='\\r')\n",
    "        except:\n",
    "            counter2+=1\n",
    "            LinkNotfound.append(Link)\n",
    "            print(\"found-> \"+ str(counter) + \"/\"+ str(counter2)+ \" of \"+ str(len(Liste)),flush=True,end='\\r')\n",
    "        \n",
    "    return Headline,Hauptartikel,News,LinkNotfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus, Other =getCorpusFromLink(AllSites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinksForAllNews = getLinksFromCorpus(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found-> 539of 540 540\r"
     ]
    }
   ],
   "source": [
    "AlleHeadlines, AlleHauptartikel, AlleWebsiten, LinkNotfound =getNewsFromLinks(LinksForAllNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Headline':AlleHeadlines,'Hauptartikel':AlleHauptartikel,'Link':AlleWebsiten})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Hauptartikel</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POL-F: 190418 - 444 Frankfurt-Griesheim: Unfal...</td>\n",
       "      <td>\\n\\nFrankfurt (ots)\\n (ka) Heute Morgen stieße...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POL-F: 190418 - 443 Frankfurt-Stadtgebiet: Ges...</td>\n",
       "      <td>\\n\\nFrankfurt (ots)\\n (fue) Auch in der kommen...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POL-F: 190418 - 442 Frankfurt-Oberrad: Wohnung...</td>\n",
       "      <td>\\n\\nFrankfurt (ots)\\n (fue) Die 68-jährige Mie...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POL-F: 190418 - 441 Bundesautobahn 5: Zeugensuche</td>\n",
       "      <td>\\n\\nFrankfurt (ots)\\n (fue) Am Mittwoch, den 1...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POL-F: 190417 - 440 Frankfurt-Innenstadt: Fest...</td>\n",
       "      <td>\\n\\nFrankfurt (ots)\\n (em) Gestern (16.04.2019...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  POL-F: 190418 - 444 Frankfurt-Griesheim: Unfal...   \n",
       "1  POL-F: 190418 - 443 Frankfurt-Stadtgebiet: Ges...   \n",
       "2  POL-F: 190418 - 442 Frankfurt-Oberrad: Wohnung...   \n",
       "3  POL-F: 190418 - 441 Bundesautobahn 5: Zeugensuche   \n",
       "4  POL-F: 190417 - 440 Frankfurt-Innenstadt: Fest...   \n",
       "\n",
       "                                        Hauptartikel  \\\n",
       "0  \\n\\nFrankfurt (ots)\\n (ka) Heute Morgen stieße...   \n",
       "1  \\n\\nFrankfurt (ots)\\n (fue) Auch in der kommen...   \n",
       "2  \\n\\nFrankfurt (ots)\\n (fue) Die 68-jährige Mie...   \n",
       "3  \\n\\nFrankfurt (ots)\\n (fue) Am Mittwoch, den 1...   \n",
       "4  \\n\\nFrankfurt (ots)\\n (em) Gestern (16.04.2019...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.presseportal.de/blaulicht/pm/4970/...  \n",
       "1  https://www.presseportal.de/blaulicht/pm/4970/...  \n",
       "2  https://www.presseportal.de/blaulicht/pm/4970/...  \n",
       "3  https://www.presseportal.de/blaulicht/pm/4970/...  \n",
       "4  https://www.presseportal.de/blaulicht/pm/4970/...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace escape sharacters\n",
    "df['Headline']= df[\"Headline\"].apply(lambda st: st.replace(\"\\t\",\" \"))\n",
    "df['Headline']= df[\"Headline\"].apply(lambda st: st.replace(\"\\n\",\" \"))\n",
    "df['Hauptartikel']= df[\"Hauptartikel\"].apply(lambda st: st.replace(\"\\n\",\" \"))\n",
    "\n",
    "df[\"date\"] =df.Headline.str.extract('(\\d+)')\n",
    "df['date'] = df['date'].apply(lambda x: \"{}{}\".format('20', x))\n",
    "#ffill if date is not found\n",
    "df['date'] = df['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d') if len(x)==8 else \"\").fillna(method='ffill')\n",
    "df['Headline'] = df['Headline'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extract case\n",
    "#df[\"case\"] =df.Headline.str.extract('(\\s\\d{3,4}\\s)')\n",
    "#df[\"case\"] = df[\"case\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Find index of Case in Headline\n",
    "#df['col3'] = [i2.index(i1) for i1,i2 in zip(df.case,df.Headline)]\n",
    "#COnvert into numeric\n",
    "#df['col3'] = pd.to_numeric(df['col3'] )\n",
    "#Remove beginning of Headline\n",
    "#df['Headline'] = [A[B:] for A, B in zip(df[\"Headline\"], df[\"col3\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Strip whitespaces\n",
    "df['Headline']= df[\"Headline\"].apply(lambda st: st.lstrip())\n",
    "#Remove beginning from Headline (remove 4digit Number)\n",
    "df['Headline']=df['Headline'].str.replace(\"\\d{4}\",\"\",regex=True)\n",
    "df['Headline']=df['Headline'].str.replace(\"\\d{3}\",\"\",regex=True)\n",
    "df['Headline']=df['Headline'].str.replace(\"POL-F:\",\"\")\n",
    "\n",
    "#Strip whitespaces again\n",
    "df['Headline']= df[\"Headline\"].apply(lambda st: st.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find nth substring\n",
    "def find_nth(s, substr, n):\n",
    "    i = 0\n",
    "    while n >= 0:\n",
    "        n -= 1\n",
    "        i = s.find(substr, i + 1)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Location\n",
    "df['Location']= df[\"Headline\"].apply(lambda st: st[0:st.find(\":\")])\n",
    "#remove Stuff from Location\n",
    "df['Location']=df['Location'].str.replace(\"/\",\" \")\n",
    "df['Location']=df['Location'].str.replace(\"Frankfurt\",\"\")\n",
    "df['Location']=df['Location'].str.replace(\"-\",\" \")\n",
    "df['Location']= df[\"Location\"].apply(lambda st: st.lstrip())\n",
    "#Remove Headline\n",
    "df['Headline']= df[\"Headline\"].apply(lambda st: st[st.find(\":\")+1:])\n",
    "#Strip whitespace again\n",
    "df['Headline']= df[\"Headline\"].apply(lambda st: st.lstrip())\n",
    "#Extract second location\n",
    "df['Location2']= df['Location'].str.split(' ').str[1]\n",
    "#Clean Location\n",
    "df['Location']= df['Location'].str.split(' ').str[0]\n",
    "#Remove start of Hauptartikel e.g. Frankfurt (ots) - (ka)\n",
    "df[\"Headline\"].apply(lambda st: st[st.find(\" - \")+2:find_nth(st,\" \",3)])\n",
    "#Extract start of Hauptartikel\n",
    "df[\"Beschreibung\"]= df[\"Hauptartikel\"].apply(lambda st: st[0:find_nth(st,\")\",1)+1])\n",
    "#Remove start from Hauptartikel\n",
    "df[\"Hauptartikel\"]= df[\"Hauptartikel\"].apply(lambda st: st[find_nth(st,\")\",1)+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Headline        539\n",
       "Hauptartikel    539\n",
       "Link            539\n",
       "date            539\n",
       "Location        539\n",
       "Location2       102\n",
       "Beschreibung    539\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Test.csv\",sep=\"@\",encoding=\"UTF-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Hauptartikel</th>\n",
       "      <th>Link</th>\n",
       "      <th>date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location2</th>\n",
       "      <th>Beschreibung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unfall zwischen Auto und Straßenbahn</td>\n",
       "      <td>Heute Morgen stießen auf der Mainzer Landstra...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>Griesheim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (ka)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geschwindigkeitsmessungen</td>\n",
       "      <td>Auch in der kommenden Woche werden im Frankfu...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>Stadtgebiet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (fue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wohnungsbrand</td>\n",
       "      <td>Die 68-jährige Mieterin einer Wohnung in der ...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>Oberrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (fue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zeugensuche</td>\n",
       "      <td>Am Mittwoch, den 17. April 2019, gegen 22.10 ...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>Bundesautobahn</td>\n",
       "      <td></td>\n",
       "      <td>Frankfurt (ots)  (fue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Festnahme eines Jugendlichen</td>\n",
       "      <td>Gestern (16.04.2019) hat ein 14-Jähriger glei...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-17</td>\n",
       "      <td>Innenstadt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Headline  \\\n",
       "0  Unfall zwischen Auto und Straßenbahn   \n",
       "1             Geschwindigkeitsmessungen   \n",
       "2                         Wohnungsbrand   \n",
       "3                           Zeugensuche   \n",
       "4          Festnahme eines Jugendlichen   \n",
       "\n",
       "                                        Hauptartikel  \\\n",
       "0   Heute Morgen stießen auf der Mainzer Landstra...   \n",
       "1   Auch in der kommenden Woche werden im Frankfu...   \n",
       "2   Die 68-jährige Mieterin einer Wohnung in der ...   \n",
       "3   Am Mittwoch, den 17. April 2019, gegen 22.10 ...   \n",
       "4   Gestern (16.04.2019) hat ein 14-Jähriger glei...   \n",
       "\n",
       "                                                Link       date  \\\n",
       "0  https://www.presseportal.de/blaulicht/pm/4970/... 2019-04-18   \n",
       "1  https://www.presseportal.de/blaulicht/pm/4970/... 2019-04-18   \n",
       "2  https://www.presseportal.de/blaulicht/pm/4970/... 2019-04-18   \n",
       "3  https://www.presseportal.de/blaulicht/pm/4970/... 2019-04-18   \n",
       "4  https://www.presseportal.de/blaulicht/pm/4970/... 2019-04-17   \n",
       "\n",
       "         Location Location2              Beschreibung  \n",
       "0       Griesheim       NaN     Frankfurt (ots)  (ka)  \n",
       "1     Stadtgebiet       NaN    Frankfurt (ots)  (fue)  \n",
       "2         Oberrad       NaN    Frankfurt (ots)  (fue)  \n",
       "3  Bundesautobahn              Frankfurt (ots)  (fue)  \n",
       "4      Innenstadt       NaN     Frankfurt (ots)  (em)  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
