{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Linking successful\n",
      "C:\\Users\\Markus.Haftstein.ADASTRACORPNET\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\de_core_news_sm\n",
      "-->\n",
      "C:\\Users\\Markus.Haftstein.ADASTRACORPNET\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\data\\de_core_news_sm\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'char_split.py'; 'char_split' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9e25af2c23cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mchar_split\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'char_split.py'; 'char_split' is not a package"
     ]
    }
   ],
   "source": [
    "#from urllib.request import urlopen\n",
    "import spacy\n",
    "from spacy.cli import link\n",
    "from spacy.util import get_package_path\n",
    "from gensim.models import LsiModel\n",
    "\n",
    "model_name = \"de_core_news_sm\"\n",
    "package_path = get_package_path(model_name)\n",
    "link(model_name, model_name, force=True, model_path=package_path)\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "import operator\n",
    "import numpy as np\n",
    "import os.path\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n",
    "import char_split.py\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf= pd.read_csv(r\"../out/Polizeiberichte.csv\",sep=\";\",encoding=\"UTF-8\")\n",
    "newdf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\w\n",
      "<ipython-input-11-45cd58dc3595>:1: DeprecationWarning: invalid escape sequence \\w\n",
      "  newdf[\"Clean_Hauptartikel\"] = newdf['Hauptartikel'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "newdf[\"Clean_Hauptartikel\"] = newdf['Hauptartikel'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLemma(column):\n",
    "    \"\"\"return the Lemmas for a given column\"\"\"\n",
    "    doc = nlp(text=column)\n",
    "    CleanWordList=[]\n",
    "    for token in doc:\n",
    "        CleanWordList.append(token.lemma_)\n",
    "    CleanWord = \" \".join(CleanWordList)\n",
    "    return CleanWord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = open(r\"C:\\Users\\Markus.Haftstein.ADASTRACORPNET\\PycharmProjects\\polizeiberichte_scraper\\Stopwords1.txt\", \"r\")\n",
    "stop.close()\n",
    "stop = open(r\"C:\\Users\\Markus.Haftstein.ADASTRACORPNET\\PycharmProjects\\polizeiberichte_scraper\\Stopwords1.txt\", \"r\")\n",
    "stop = list(stop)\n",
    "stop = list(map(lambda s: s.strip(),stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getElement(Liste):\n",
    "    return ' '.join(Liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-17-419943424850>:1: DeprecationWarning: invalid escape sequence \\d\n",
      "  newdf[\"Headline\"].str.replace('\\d+', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      Fahrraddieb verirrt sich in Polizeirevier-Inne...\n",
       "1      Motorradfahrer stürzt & Unfallverursacher flie...\n",
       "2                     Motorradfahrer verunglückt tödlich\n",
       "3          \"Car-Freitag\" - Fazit der Frankfurter Polizei\n",
       "4                Polizei erwischt Täter auf frischer Tat\n",
       "5      Oberaurach/Landkreis Hassberge/Bamberg/Frankfu...\n",
       "6                   Unfall zwischen Auto und Straßenbahn\n",
       "7                              Geschwindigkeitsmessungen\n",
       "8                                          Wohnungsbrand\n",
       "9                                            Zeugensuche\n",
       "10                          Festnahme eines Jugendlichen\n",
       "11                                   Lastwagen umgekippt\n",
       "12               Frau an Straßenbahnhaltestelle verletzt\n",
       "13                                          Zeugensuche!\n",
       "14                               Schwerer Verkehrsunfall\n",
       "15                                        Verkehrsunfall\n",
       "16                                      Pkw aufgebrochen\n",
       "17               Geklauter Roller schnell wiedergefunden\n",
       "18                  Drogendealer rennt bei Kontrolle weg\n",
       "19        -jähriger Autofahrer flüchtet nicht ohne Grund\n",
       "20                    Schreckschusswaffen sichergestellt\n",
       "21                 Flüchtiger verursacht weiteren Unfall\n",
       "22     Pressemeldung von Ordnungsamt und Feuerwehr de...\n",
       "23                                          Steinewerfer\n",
       "24                               Drogendealer geschnappt\n",
       "25            Versuchtes Tötungsdelikt - Zeugen gesucht!\n",
       "26                             Geschwindigkeitsmessungen\n",
       "27          Taschendieb schlägt zu und wird festgenommen\n",
       "28     Verdacht des versuchten Totschlags - Zeugen ge...\n",
       "29     Pressemitteilung des Polizeipräsidiums Südosth...\n",
       "                             ...                        \n",
       "510                            Unfall, Flucht, Festnahme\n",
       "511                    Unbekannter überfällt Kassiererin\n",
       "512                  Unfall zwischen Pkw und Straßenbahn\n",
       "513                            Drogendealer festgenommen\n",
       "514                                     Kiosk überfallen\n",
       "515           Polizisten kontrollieren das richtige Auto\n",
       "516                   -Jähriger wurde um Bargeld beraubt\n",
       "517                                 -Jähriger ausgeraubt\n",
       "518               -Jährigen mit Hantelstange angegriffen\n",
       "519                       -jähriger Mann tot aufgefunden\n",
       "520                       Mountainbike Fahrer überfallen\n",
       "521                                        Fahrzeugbrand\n",
       "522            Schwerer Verkehrsunfall - Zeugen gesucht!\n",
       "523                                        Wohnungsbrand\n",
       "524                         Feuer in Dachgeschosswohnung\n",
       "525    Fahrradfahrer verstorben - Nachtrag zu unserer...\n",
       "526    Schwerer Verkehrsunfall - Fahrzeug überschlägt...\n",
       "527                            Geschwindigkeitsmessungen\n",
       "528             Brennendes Papier in Autofelgen gesteckt\n",
       "529          Schüsse vom Balkon führen zu Polizeieinsatz\n",
       "530                              Schwerer Verkehrsunfall\n",
       "531       Verkehrsunfall - Fahrradfahrer schwer verletzt\n",
       "532                     Wenn Polizisten angedealt werden\n",
       "533             Unbekannter bedroht -Jährigen mit Messer\n",
       "534    Diebesbande bestiehlt Konzertbesucher - Polize...\n",
       "535            Motorradfahrer bei Unfall schwer verletzt\n",
       "536                                  Räuber festgenommen\n",
       "537                   Verkehrsunfallflucht - Zeugensuche\n",
       "538                              Schwerer Verkehrsunfall\n",
       "539                                Taxifahrer überfallen\n",
       "Name: Headline, Length: 540, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf[\"Headline\"].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:10: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:10: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\w\n",
      "<>:10: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-18-d47efeeea282>:5: DeprecationWarning: invalid escape sequence \\w\n",
      "  Column = Column.str.replace('[^\\w\\s]','')\n",
      "<ipython-input-18-d47efeeea282>:10: DeprecationWarning: invalid escape sequence \\d\n",
      "  Column = Column.str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "def getCleanColumn(Column):\n",
    "    \"\"\"Clean the whole column. Get lemmas, remove stopwords, white spaces, digits and transform to lower\"\"\"\n",
    "    Column = Column.apply(getLemma)\n",
    "    Column = pd.Series(Column)\n",
    "    Column = Column.str.replace('[^\\w\\s]','')\n",
    "    Column = Column.str.lower()\n",
    "    Column = Column.apply(lambda x: [item for item in x.split() if item not in stop])\n",
    "    Column = pd.Series(Column)\n",
    "    Column = Column.apply(getElement)\n",
    "    Column = Column.str.replace('\\d+', '')\n",
    "    Column = Column.apply(lambda x: [item for item in x.split() if item not in stop])\n",
    "    Column = Column.apply(getElement)\n",
    "    Column = pd.DataFrame(Column)\n",
    "    return Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      in der nacht von sonntag 21042019 auf montag...\n",
       "1      am samstagnachmittag 20042019 stürzen einen ...\n",
       "2      heute vormittag 20042019 stürzen einen 66jäh...\n",
       "3      der kontrolleinheit autoposer raser und tune...\n",
       "4      in der vergangen nacht 19042019 haben einen ...\n",
       "Name: Clean_Hauptartikel, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lemmas = newdf[\"Clean_Hauptartikel\"].apply(getLemma)\n",
    "Lemmas = pd.DataFrame(Lemmas)\n",
    "Lemmas[\"Clean_Hauptartikel\"]= Lemmas[\"Clean_Hauptartikel\"].str.lower()\n",
    "Lemmas[\"Clean_Hauptartikel\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Hauptartikel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[21042019, 22042019, verirren, 26jähriger, fah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[samstagnachmittag, 20042019, stürzen, 60jähri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20042019, stürzen, 66jähriger, motorradfahrer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kontrolleinheit, autoposer, raser, tuner, kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[19042019, 27jähriger, pkw, aufbrechen, wertge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Clean_Hauptartikel\n",
       "0  [21042019, 22042019, verirren, 26jähriger, fah...\n",
       "1  [samstagnachmittag, 20042019, stürzen, 60jähri...\n",
       "2  [20042019, stürzen, 66jähriger, motorradfahrer...\n",
       "3  [kontrolleinheit, autoposer, raser, tuner, kar...\n",
       "4  [19042019, 27jähriger, pkw, aufbrechen, wertge..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lemmas = Lemmas[\"Clean_Hauptartikel\"].apply(lambda x: [item for item in x.split() if item not in stop])\n",
    "Lemmas = pd.DataFrame(Lemmas)\n",
    "Lemmas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "<ipython-input-21-be755fd31be7>:2: DeprecationWarning: invalid escape sequence \\d\n",
      "  Lemmas[\"liststring\"] = Lemmas[\"liststring\"].str.replace('\\d+', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Hauptartikel</th>\n",
       "      <th>liststring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[21042019, 22042019, verirren, 26jähriger, fah...</td>\n",
       "      <td>[verirren, fahrraddieb, innenhof, fahren, been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[samstagnachmittag, 20042019, stürzen, 60jähri...</td>\n",
       "      <td>[samstagnachmittag, stürzen, motorrad, fahrtri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20042019, stürzen, 66jähriger, motorradfahrer...</td>\n",
       "      <td>[stürzen, motorradfahrer, fahrtrichtung, köln,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kontrolleinheit, autoposer, raser, tuner, kar...</td>\n",
       "      <td>[kontrolleinheit, autoposer, raser, tuner, kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[19042019, 27jähriger, pkw, aufbrechen, wertge...</td>\n",
       "      <td>[pkw, aufbrechen, wertgegenständen, unterfange...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Clean_Hauptartikel  \\\n",
       "0  [21042019, 22042019, verirren, 26jähriger, fah...   \n",
       "1  [samstagnachmittag, 20042019, stürzen, 60jähri...   \n",
       "2  [20042019, stürzen, 66jähriger, motorradfahrer...   \n",
       "3  [kontrolleinheit, autoposer, raser, tuner, kar...   \n",
       "4  [19042019, 27jähriger, pkw, aufbrechen, wertge...   \n",
       "\n",
       "                                          liststring  \n",
       "0  [verirren, fahrraddieb, innenhof, fahren, been...  \n",
       "1  [samstagnachmittag, stürzen, motorrad, fahrtri...  \n",
       "2  [stürzen, motorradfahrer, fahrtrichtung, köln,...  \n",
       "3  [kontrolleinheit, autoposer, raser, tuner, kar...  \n",
       "4  [pkw, aufbrechen, wertgegenständen, unterfange...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lemmas['liststring'] = [' '.join(map(str, l)) for l in Lemmas['Clean_Hauptartikel']]\n",
    "Lemmas[\"liststring\"] = Lemmas[\"liststring\"].str.replace('\\d+', '')\n",
    "Lemmas['liststring'] = Lemmas['liststring'].apply(lambda x: [item for item in x.split() if item not in stop])\n",
    "Lemmas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdf[\"Clean_Hauptartikel\"] = Lemmas['liststring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(column):\n",
    "    \"\"\"Split German compund words into their most likely parts for a given column\"\"\"\n",
    "    DataFrame = column.str.split(' ', expand=True).rename(columns=lambda x: f\"string_{x+1}\")\n",
    "    for col in DataFrame.columns:\n",
    "        column = DataFrame[col]\n",
    "        column.fillna(value=\"\", inplace= True)\n",
    "        NewColumn = column.apply(char_split.split_compound)\n",
    "        NewColumn = [item[0] for item in NewColumn]\n",
    "        NewColumn = pd.DataFrame(NewColumn)\n",
    "        NewColumn.columns = [\"Confidence\", \"Word1\",\"Word2\"]\n",
    "        Keep = NewColumn[\"Confidence\"]<=0\n",
    "        NewColumn[Keep] =\" \"\n",
    "        NewColumn[\"Combine\"] = NewColumn[\"Word1\"]+\" \" + NewColumn[\"Word2\"]\n",
    "        #NewColumn[\"Combine\"] = NewColumn[\"Combine\"].str.lower()\n",
    "        DataFrame[col]=NewColumn[\"Combine\"]\n",
    "    DataFrame['All_Combined'] = DataFrame.apply(' '.join, axis=1)\n",
    "    DataFrame[\"All_Combined\"]= getCleanColumn(DataFrame[\"All_Combined\"])\n",
    "    DataFrame[\"All_Combined\"] = DataFrame[\"All_Combined\"].str.lower()\n",
    "    return DataFrame[\"All_Combined\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Hauptartikel</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location2</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Clean_Hauptartikel</th>\n",
       "      <th>CleanHeadline</th>\n",
       "      <th>sepHeadline</th>\n",
       "      <th>allWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fahrraddieb verirrt sich in Polizeirevier-Inne...</td>\n",
       "      <td>In der Nacht von Sonntag (21.04.2019) auf Mon...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>Sachsenhausen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>verirren fahrraddieb innenhof fahren beenden n...</td>\n",
       "      <td>fahrraddieb verirren polizeirevierinnenhof</td>\n",
       "      <td>[fahrrad, dieb, irre, innenhof]</td>\n",
       "      <td>[fahrrad, dieb, irre, innenhof, verirren, fahr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Motorradfahrer stürzt &amp; Unfallverursacher flie...</td>\n",
       "      <td>Am Samstagnachmittag (20.04.2019) stürzte ein...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>BAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>samstagnachmittag stürzen motorrad fahrtrichtu...</td>\n",
       "      <td>motorradfahrer stürzen unfallverursacher fliehen</td>\n",
       "      <td>[motorrad, fahrer, unfall, verursacher]</td>\n",
       "      <td>[motorrad, fahrer, unfall, verursacher, samsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Motorradfahrer verunglückt tödlich</td>\n",
       "      <td>Heute Vormittag (20.04.2019) stürzte ein 66-j...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>BAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>stürzen motorradfahrer fahrtrichtung köln vers...</td>\n",
       "      <td>motorradfahrer verunglücken tödlich</td>\n",
       "      <td>[motorrad, fahrer, unglücken]</td>\n",
       "      <td>[motorrad, fahrer, unglücken, stürzen, motorra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Car-Freitag\" - Fazit der Frankfurter Polizei</td>\n",
       "      <td>Die Kontrolleinheit Autoposer, Raser und Tune...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>kontrolleinheit autoposer raser tuner kart sog...</td>\n",
       "      <td>carfreitag fazit</td>\n",
       "      <td>[car]</td>\n",
       "      <td>[car, kontrolleinheit, autoposer, raser, tuner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Polizei erwischt Täter auf frischer Tat</td>\n",
       "      <td>In der vergangenen Nacht (19.04.2019) hat ein...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>Gutleutviertel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>pkw aufbrechen wertgegenständen unterfangen be...</td>\n",
       "      <td>erwischen täter frisch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pkw, aufbrechen, wertgegenständen, unterfange...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Headline  \\\n",
       "0           0  Fahrraddieb verirrt sich in Polizeirevier-Inne...   \n",
       "1           1  Motorradfahrer stürzt & Unfallverursacher flie...   \n",
       "2           2                 Motorradfahrer verunglückt tödlich   \n",
       "3           3      \"Car-Freitag\" - Fazit der Frankfurter Polizei   \n",
       "4           4            Polizei erwischt Täter auf frischer Tat   \n",
       "\n",
       "                                        Hauptartikel  \\\n",
       "0   In der Nacht von Sonntag (21.04.2019) auf Mon...   \n",
       "1   Am Samstagnachmittag (20.04.2019) stürzte ein...   \n",
       "2   Heute Vormittag (20.04.2019) stürzte ein 66-j...   \n",
       "3   Die Kontrolleinheit Autoposer, Raser und Tune...   \n",
       "4   In der vergangenen Nacht (19.04.2019) hat ein...   \n",
       "\n",
       "                                                Link        Date  \\\n",
       "0  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-22   \n",
       "1  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-22   \n",
       "2  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-20   \n",
       "3  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-20   \n",
       "4  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-19   \n",
       "\n",
       "         Location Location2             Beschreibung  \\\n",
       "0   Sachsenhausen       NaN    Frankfurt (ots)  (em)   \n",
       "1             BAB       NaN    Frankfurt (ots)  (em)   \n",
       "2             BAB       NaN    Frankfurt (ots)  (em)   \n",
       "3             NaN       NaN    Frankfurt (ots)  (em)   \n",
       "4  Gutleutviertel       NaN    Frankfurt (ots)  (em)   \n",
       "\n",
       "                                  Clean_Hauptartikel  \\\n",
       "0  verirren fahrraddieb innenhof fahren beenden n...   \n",
       "1  samstagnachmittag stürzen motorrad fahrtrichtu...   \n",
       "2  stürzen motorradfahrer fahrtrichtung köln vers...   \n",
       "3  kontrolleinheit autoposer raser tuner kart sog...   \n",
       "4  pkw aufbrechen wertgegenständen unterfangen be...   \n",
       "\n",
       "                                      CleanHeadline  \\\n",
       "0        fahrraddieb verirren polizeirevierinnenhof   \n",
       "1  motorradfahrer stürzen unfallverursacher fliehen   \n",
       "2               motorradfahrer verunglücken tödlich   \n",
       "3                                  carfreitag fazit   \n",
       "4                            erwischen täter frisch   \n",
       "\n",
       "                               sepHeadline  \\\n",
       "0          [fahrrad, dieb, irre, innenhof]   \n",
       "1  [motorrad, fahrer, unfall, verursacher]   \n",
       "2            [motorrad, fahrer, unglücken]   \n",
       "3                                    [car]   \n",
       "4                                       []   \n",
       "\n",
       "                                            allWords  \n",
       "0  [fahrrad, dieb, irre, innenhof, verirren, fahr...  \n",
       "1  [motorrad, fahrer, unfall, verursacher, samsta...  \n",
       "2  [motorrad, fahrer, unglücken, stürzen, motorra...  \n",
       "3  [car, kontrolleinheit, autoposer, raser, tuner...  \n",
       "4  [pkw, aufbrechen, wertgegenständen, unterfange...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf[\"CleanHeadline\"]= getCleanColumn(newdf[\"Headline\"])\n",
    "newdf[\"sepHeadline\"] = split_words(newdf['CleanHeadline'])\n",
    "newdf[\"Clean_Hauptartikel\"] =newdf[\"Clean_Hauptartikel\"].apply(getElement)\n",
    "newdf[\"allWords\"]= newdf[\"sepHeadline\"]+\" \"+ newdf[\"Clean_Hauptartikel\"]+\" \" + newdf[\"CleanHeadline\"]\n",
    "newdf[\"allWords\"] = newdf[\"allWords\"].apply(lambda x: [item for item in x.split()])\n",
    "dataset = (newdf[\"allWords\"])\n",
    "dataset_head = newdf[\"sepHeadline\"]+\" \" +newdf[\"CleanHeadline\"]\n",
    "dataset_head= dataset_head.apply(lambda x: [item for item in x.split()])\n",
    "newdf[\"sepHeadline\"] = newdf[\"sepHeadline\"].apply(lambda x: [item for item in x.split()])\n",
    "\n",
    "\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# be sure to split sentence before feed into Dictionary\n",
    "#dataset = [d.split() for d in dataset]\n",
    "\n",
    "vocab = gensim.corpora.Dictionary(dataset)\n",
    "vocab_heads = gensim.corpora.Dictionary(dataset_head)\n",
    "\n",
    "bow_corpus = [vocab.doc2bow(doc) for doc in dataset]\n",
    "bow_corpus_heads = [vocab.doc2bow(doc) for doc in dataset_head]\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "tfidf_head = models.TfidfModel(bow_corpus_heads)\n",
    "\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "corpus_tfidf_head = tfidf[bow_corpus_heads]\n",
    "\n",
    "\n",
    "data = newdf[\"allWords\"].apply(getElement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.002*\"täter\" + 0.001*\"gramm\" + 0.001*\"fahren\" + 0.001*\"handtasche\" + 0.001*\"dunkel\" + 0.001*\"groß\" + 0.001*\"cm\" + 0.001*\"schwer\" + 0.001*\"unfall\" + 0.001*\"maßnahme\"\n",
      "Topic: 1 Word: 0.001*\"fahrer\" + 0.001*\"täter\" + 0.001*\"gramm\" + 0.001*\"verkehrsunfall\" + 0.001*\"unfall\" + 0.001*\"dunkel\" + 0.001*\"fahren\" + 0.001*\"schwer\" + 0.001*\"bmw\" + 0.001*\"renault\"\n",
      "Topic: 2 Word: 0.002*\"vw\" + 0.002*\"brand\" + 0.001*\"unfall\" + 0.001*\"auto\" + 0.001*\"wohnung\" + 0.001*\"täter\" + 0.001*\"verletzen\" + 0.001*\"mercedes\" + 0.001*\"schwer\" + 0.001*\"fußgänger\"\n",
      "Topic: 3 Word: 0.002*\"brand\" + 0.001*\"droge\" + 0.001*\"straße\" + 0.001*\"polizeipräsidium\" + 0.001*\"täter\" + 0.001*\"fahrzeug\" + 0.001*\"wohnung\" + 0.001*\"auto\" + 0.001*\"verletzen\" + 0.001*\"mercedes\"\n",
      "Topic: 4 Word: 0.001*\"täter\" + 0.001*\"kiosk\" + 0.001*\"dieb\" + 0.001*\"pkw\" + 0.001*\"einbrecher\" + 0.001*\"hütte\" + 0.001*\"fest\" + 0.001*\"person\" + 0.001*\"bundesautobahn\" + 0.001*\"diebesgut\"\n",
      "Topic: 5 Word: 0.002*\"unfall\" + 0.001*\"täter\" + 0.001*\"messer\" + 0.001*\"sexuell\" + 0.001*\"kiosk\" + 0.001*\"verletzen\" + 0.001*\"straße\" + 0.001*\"pkw\" + 0.001*\"fahrzeug\" + 0.001*\"person\"\n",
      "Topic: 6 Word: 0.007*\"autobahnkreuz\" + 0.007*\"bundesautobahn\" + 0.004*\"dreieck\" + 0.003*\"geschwindigkeitsmessungen\" + 0.003*\"richtung\" + 0.002*\"bundesstraße\" + 0.002*\"anschlussstelle\" + 0.001*\"homburg\" + 0.001*\"täter\" + 0.001*\"überfallen\"\n"
     ]
    }
   ],
   "source": [
    "#Running LDA using TF-IDF\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=7, id2word=vocab, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(7):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopics(lda_model_tfidf,bow_corpus):\n",
    "    TopicList=[]\n",
    "    for i in range(0, len(lda_model_tfidf.get_document_topics(bow_corpus))):\n",
    "        TopicList.append(max(lda_model_tfidf.get_document_topics(bow_corpus[i]), key = lambda x : x[1]))\n",
    "    return TopicList\n",
    "TopicList = getTopics(lda_model_tfidf,bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Hauptartikel</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location2</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Clean_Hauptartikel</th>\n",
       "      <th>CleanHeadline</th>\n",
       "      <th>sepHeadline</th>\n",
       "      <th>allWords</th>\n",
       "      <th>TopicNumber</th>\n",
       "      <th>TopicProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fahrraddieb verirrt sich in Polizeirevier-Inne...</td>\n",
       "      <td>In der Nacht von Sonntag (21.04.2019) auf Mon...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>Sachsenhausen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>verirren fahrraddieb innenhof fahren beenden n...</td>\n",
       "      <td>fahrraddieb verirren polizeirevierinnenhof</td>\n",
       "      <td>[fahrrad, dieb, irre, innenhof]</td>\n",
       "      <td>[fahrrad, dieb, irre, innenhof, verirren, fahr...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Motorradfahrer stürzt &amp; Unfallverursacher flie...</td>\n",
       "      <td>Am Samstagnachmittag (20.04.2019) stürzte ein...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>BAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>samstagnachmittag stürzen motorrad fahrtrichtu...</td>\n",
       "      <td>motorradfahrer stürzen unfallverursacher fliehen</td>\n",
       "      <td>[motorrad, fahrer, unfall, verursacher]</td>\n",
       "      <td>[motorrad, fahrer, unfall, verursacher, samsta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Motorradfahrer verunglückt tödlich</td>\n",
       "      <td>Heute Vormittag (20.04.2019) stürzte ein 66-j...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>BAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>stürzen motorradfahrer fahrtrichtung köln vers...</td>\n",
       "      <td>motorradfahrer verunglücken tödlich</td>\n",
       "      <td>[motorrad, fahrer, unglücken]</td>\n",
       "      <td>[motorrad, fahrer, unglücken, stürzen, motorra...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Car-Freitag\" - Fazit der Frankfurter Polizei</td>\n",
       "      <td>Die Kontrolleinheit Autoposer, Raser und Tune...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>kontrolleinheit autoposer raser tuner kart sog...</td>\n",
       "      <td>carfreitag fazit</td>\n",
       "      <td>[car]</td>\n",
       "      <td>[car, kontrolleinheit, autoposer, raser, tuner...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.992420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Polizei erwischt Täter auf frischer Tat</td>\n",
       "      <td>In der vergangenen Nacht (19.04.2019) hat ein...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>Gutleutviertel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>pkw aufbrechen wertgegenständen unterfangen be...</td>\n",
       "      <td>erwischen täter frisch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pkw, aufbrechen, wertgegenständen, unterfange...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Headline  \\\n",
       "0           0  Fahrraddieb verirrt sich in Polizeirevier-Inne...   \n",
       "1           1  Motorradfahrer stürzt & Unfallverursacher flie...   \n",
       "2           2                 Motorradfahrer verunglückt tödlich   \n",
       "3           3      \"Car-Freitag\" - Fazit der Frankfurter Polizei   \n",
       "4           4            Polizei erwischt Täter auf frischer Tat   \n",
       "\n",
       "                                        Hauptartikel  \\\n",
       "0   In der Nacht von Sonntag (21.04.2019) auf Mon...   \n",
       "1   Am Samstagnachmittag (20.04.2019) stürzte ein...   \n",
       "2   Heute Vormittag (20.04.2019) stürzte ein 66-j...   \n",
       "3   Die Kontrolleinheit Autoposer, Raser und Tune...   \n",
       "4   In der vergangenen Nacht (19.04.2019) hat ein...   \n",
       "\n",
       "                                                Link        Date  \\\n",
       "0  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-22   \n",
       "1  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-22   \n",
       "2  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-20   \n",
       "3  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-20   \n",
       "4  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-19   \n",
       "\n",
       "         Location Location2             Beschreibung  \\\n",
       "0   Sachsenhausen       NaN    Frankfurt (ots)  (em)   \n",
       "1             BAB       NaN    Frankfurt (ots)  (em)   \n",
       "2             BAB       NaN    Frankfurt (ots)  (em)   \n",
       "3             NaN       NaN    Frankfurt (ots)  (em)   \n",
       "4  Gutleutviertel       NaN    Frankfurt (ots)  (em)   \n",
       "\n",
       "                                  Clean_Hauptartikel  \\\n",
       "0  verirren fahrraddieb innenhof fahren beenden n...   \n",
       "1  samstagnachmittag stürzen motorrad fahrtrichtu...   \n",
       "2  stürzen motorradfahrer fahrtrichtung köln vers...   \n",
       "3  kontrolleinheit autoposer raser tuner kart sog...   \n",
       "4  pkw aufbrechen wertgegenständen unterfangen be...   \n",
       "\n",
       "                                      CleanHeadline  \\\n",
       "0        fahrraddieb verirren polizeirevierinnenhof   \n",
       "1  motorradfahrer stürzen unfallverursacher fliehen   \n",
       "2               motorradfahrer verunglücken tödlich   \n",
       "3                                  carfreitag fazit   \n",
       "4                            erwischen täter frisch   \n",
       "\n",
       "                               sepHeadline  \\\n",
       "0          [fahrrad, dieb, irre, innenhof]   \n",
       "1  [motorrad, fahrer, unfall, verursacher]   \n",
       "2            [motorrad, fahrer, unglücken]   \n",
       "3                                    [car]   \n",
       "4                                       []   \n",
       "\n",
       "                                            allWords  TopicNumber  TopicProb  \n",
       "0  [fahrrad, dieb, irre, innenhof, verirren, fahr...            5   0.931378  \n",
       "1  [motorrad, fahrer, unfall, verursacher, samsta...            0   0.942221  \n",
       "2  [motorrad, fahrer, unglücken, stürzen, motorra...            2   0.979971  \n",
       "3  [car, kontrolleinheit, autoposer, raser, tuner...            3   0.992420  \n",
       "4  [pkw, aufbrechen, wertgegenständen, unterfange...            0   0.846756  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicList = pd.DataFrame(TopicList)\n",
    "newdf[\"TopicNumber\"]= TopicList.iloc[:,0]\n",
    "newdf[\"TopicProb\"]= TopicList.iloc[:,1]\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc_clean):\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    # generate LDA model\n",
    "    return dictionary,doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gensim_lsa_model(doc_clean,number_of_topics,words):\n",
    "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
    "    # generate LSA model\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "    print(lsamodel.print_topics(num_topics=number_of_topics, num_words=words))\n",
    "    return lsamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Input   : dictionary : Gensim dictionary\n",
    "              corpus : Gensim corpus\n",
    "              texts : List of input texts\n",
    "              stop : Max num of topics\n",
    "    purpose : Compute c_v coherence for various number of topics\n",
    "    Output  : model_list : List of LSA topic models\n",
    "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, stop, step):\n",
    "        # generate LSA model\n",
    "        model = LsiModel(doc_term_matrix, num_topics=num_topics, id2word = dictionary)  # train model\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(doc_clean,start, stop, step):\n",
    "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix,doc_clean,\n",
    "                                                            stop, start, step)\n",
    "    # Show graph\n",
    "    x = range(start, stop, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#start,stop,step=2,12,1\n",
    "#plot_graph(newdf[\"allWords\"],start,stop,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMyTopic(row, Model):\n",
    "    bow = vocab.doc2bow(row)\n",
    "    Topic = max((Model[bow]), key= lambda x: x[1])\n",
    "    return Topic[0]\n",
    "\n",
    "def getMyTopic1(row, Model):\n",
    "    bow = vocab.doc2bow(row)\n",
    "    Topic = max((Model[bow]), key= lambda x: x[1])\n",
    "    return Topic[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Hauptartikel</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location2</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Clean_Hauptartikel</th>\n",
       "      <th>CleanHeadline</th>\n",
       "      <th>sepHeadline</th>\n",
       "      <th>allWords</th>\n",
       "      <th>TopicNumber</th>\n",
       "      <th>TopicProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fahrraddieb verirrt sich in Polizeirevier-Inne...</td>\n",
       "      <td>In der Nacht von Sonntag (21.04.2019) auf Mon...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>Sachsenhausen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>verirren fahrraddieb innenhof fahren beenden n...</td>\n",
       "      <td>fahrraddieb verirren polizeirevierinnenhof</td>\n",
       "      <td>[fahrrad, dieb, irre, innenhof]</td>\n",
       "      <td>[fahrrad, dieb, irre, innenhof, verirren, fahr...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Motorradfahrer stürzt &amp; Unfallverursacher flie...</td>\n",
       "      <td>Am Samstagnachmittag (20.04.2019) stürzte ein...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>BAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>samstagnachmittag stürzen motorrad fahrtrichtu...</td>\n",
       "      <td>motorradfahrer stürzen unfallverursacher fliehen</td>\n",
       "      <td>[motorrad, fahrer, unfall, verursacher]</td>\n",
       "      <td>[motorrad, fahrer, unfall, verursacher, samsta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Motorradfahrer verunglückt tödlich</td>\n",
       "      <td>Heute Vormittag (20.04.2019) stürzte ein 66-j...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>BAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>stürzen motorradfahrer fahrtrichtung köln vers...</td>\n",
       "      <td>motorradfahrer verunglücken tödlich</td>\n",
       "      <td>[motorrad, fahrer, unglücken]</td>\n",
       "      <td>[motorrad, fahrer, unglücken, stürzen, motorra...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Car-Freitag\" - Fazit der Frankfurter Polizei</td>\n",
       "      <td>Die Kontrolleinheit Autoposer, Raser und Tune...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>kontrolleinheit autoposer raser tuner kart sog...</td>\n",
       "      <td>carfreitag fazit</td>\n",
       "      <td>[car]</td>\n",
       "      <td>[car, kontrolleinheit, autoposer, raser, tuner...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.992420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Polizei erwischt Täter auf frischer Tat</td>\n",
       "      <td>In der vergangenen Nacht (19.04.2019) hat ein...</td>\n",
       "      <td>https://www.presseportal.de/blaulicht/pm/4970/...</td>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>Gutleutviertel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frankfurt (ots)  (em)</td>\n",
       "      <td>pkw aufbrechen wertgegenständen unterfangen be...</td>\n",
       "      <td>erwischen täter frisch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pkw, aufbrechen, wertgegenständen, unterfange...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Headline  \\\n",
       "0           0  Fahrraddieb verirrt sich in Polizeirevier-Inne...   \n",
       "1           1  Motorradfahrer stürzt & Unfallverursacher flie...   \n",
       "2           2                 Motorradfahrer verunglückt tödlich   \n",
       "3           3      \"Car-Freitag\" - Fazit der Frankfurter Polizei   \n",
       "4           4            Polizei erwischt Täter auf frischer Tat   \n",
       "\n",
       "                                        Hauptartikel  \\\n",
       "0   In der Nacht von Sonntag (21.04.2019) auf Mon...   \n",
       "1   Am Samstagnachmittag (20.04.2019) stürzte ein...   \n",
       "2   Heute Vormittag (20.04.2019) stürzte ein 66-j...   \n",
       "3   Die Kontrolleinheit Autoposer, Raser und Tune...   \n",
       "4   In der vergangenen Nacht (19.04.2019) hat ein...   \n",
       "\n",
       "                                                Link        Date  \\\n",
       "0  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-22   \n",
       "1  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-22   \n",
       "2  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-20   \n",
       "3  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-20   \n",
       "4  https://www.presseportal.de/blaulicht/pm/4970/...  2019-04-19   \n",
       "\n",
       "         Location Location2             Beschreibung  \\\n",
       "0   Sachsenhausen       NaN    Frankfurt (ots)  (em)   \n",
       "1             BAB       NaN    Frankfurt (ots)  (em)   \n",
       "2             BAB       NaN    Frankfurt (ots)  (em)   \n",
       "3             NaN       NaN    Frankfurt (ots)  (em)   \n",
       "4  Gutleutviertel       NaN    Frankfurt (ots)  (em)   \n",
       "\n",
       "                                  Clean_Hauptartikel  \\\n",
       "0  verirren fahrraddieb innenhof fahren beenden n...   \n",
       "1  samstagnachmittag stürzen motorrad fahrtrichtu...   \n",
       "2  stürzen motorradfahrer fahrtrichtung köln vers...   \n",
       "3  kontrolleinheit autoposer raser tuner kart sog...   \n",
       "4  pkw aufbrechen wertgegenständen unterfangen be...   \n",
       "\n",
       "                                      CleanHeadline  \\\n",
       "0        fahrraddieb verirren polizeirevierinnenhof   \n",
       "1  motorradfahrer stürzen unfallverursacher fliehen   \n",
       "2               motorradfahrer verunglücken tödlich   \n",
       "3                                  carfreitag fazit   \n",
       "4                            erwischen täter frisch   \n",
       "\n",
       "                               sepHeadline  \\\n",
       "0          [fahrrad, dieb, irre, innenhof]   \n",
       "1  [motorrad, fahrer, unfall, verursacher]   \n",
       "2            [motorrad, fahrer, unglücken]   \n",
       "3                                    [car]   \n",
       "4                                       []   \n",
       "\n",
       "                                            allWords  TopicNumber  TopicProb  \n",
       "0  [fahrrad, dieb, irre, innenhof, verirren, fahr...            5   0.931378  \n",
       "1  [motorrad, fahrer, unfall, verursacher, samsta...            0   0.942221  \n",
       "2  [motorrad, fahrer, unglücken, stürzen, motorra...            2   0.979971  \n",
       "3  [car, kontrolleinheit, autoposer, raser, tuner...            3   0.992420  \n",
       "4  [pkw, aufbrechen, wertgegenständen, unterfange...            0   0.846756  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Safe as Excel\n",
    "newdf.to_excel(r\"C:\\Users\\Markus.Haftstein.ADASTRACORPNET\\PycharmProjects\\polizeiberichte_scraper\\MYDF.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(corpus=bow_corpus, num_topics=7, id2word=vocab)\n",
    "hdpmodel = HdpModel(corpus=bow_corpus, id2word=vocab)\n",
    "lsimodel = LsiModel(corpus=corpus_tfidf, num_topics=7, id2word=vocab)\n",
    "lsimodelUpdate = models.LsiModel(corpus_tfidf, id2word=vocab, num_topics=7)\n",
    "lsimodelUpdate.add_documents(corpus_tfidf_head, decay=0.5)  # now LSI has been trained on tfidf_corpus + another_tfidf_corpus\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=7, id2word=vocab, passes=2, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://markroxor.github.io/gensim/static/notebooks/gensim_news_classification.html\n",
    "#One of the problem with LDA is that if we train it on a large number of topics, the topics get \"lost\" among the numbers.\n",
    "#Let us see if we can dig out the best topics from the best LDA model we can produce. \n",
    "#The function below can be used to control the quality of the LDA model we produce.\n",
    "def ret_top_model():\n",
    "    \"\"\"\n",
    "    Since LDAmodel is a probabilistic model, it comes up different topics each time we run it. To control the\n",
    "    quality of the topic model we produce, we can see what the interpretability of the best topic is and keep\n",
    "    evaluating the topic model until this threshold is crossed. \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm: Final evaluated topic model\n",
    "    top_topics: ranked topics in decreasing order. List of tuples\n",
    "    \"\"\"\n",
    "    top_topics = [(0, 0)]\n",
    "    while top_topics[0][1] < 0.97:\n",
    "        lm = LdaModel(corpus=bow_corpus, id2word=vocab)\n",
    "        coherence_values = {}\n",
    "        for n, topic in lm.show_topics(num_topics=-1, formatted=False):\n",
    "            topic = [word for word, _ in topic]\n",
    "            cm = CoherenceModel(topics=[topic], texts=newdf[\"allWords\"], dictionary=vocab, window_size=10)\n",
    "            coherence_values[n] = cm.get_coherence()\n",
    "        top_topics = sorted(coherence_values.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return lm, top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m, top_topics = ret_top_model()\n",
    "#top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-a289071cb302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhdptopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopicid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhdpmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mldatopics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopicid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlda_lsi_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopicid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopicid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_v\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_topics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlda_model_tfidf_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopicid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlda_model_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_topics' is not defined"
     ]
    }
   ],
   "source": [
    "lsitopics = [[word for word, prob in topic] for topicid, topic in lsimodel.show_topics(formatted=False)]\n",
    "lsitopics_update = [[word for word, prob in topic] for topicid, topic in lsimodelUpdate.show_topics(formatted=False)]\n",
    "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]\n",
    "lda_lsi_topics = [[word for word, prob in lm.show_topic(topicid)] for topicid, c_v in top_topics]\n",
    "lda_model_tfidf_topics = [[word for word, prob in topic] for topicid, topic in lda_model_tfidf.show_topics(formatted=False)]\n",
    "\n",
    "\n",
    "lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=newdf[\"allWords\"], dictionary=vocab, window_size=10).get_coherence()\n",
    "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=newdf[\"allWords\"], dictionary=vocab, window_size=10).get_coherence()\n",
    "lda_coherence = CoherenceModel(topics=ldatopics, texts=newdf[\"allWords\"], dictionary=vocab, window_size=10).get_coherence()\n",
    "#lda_lsi_coherence = CoherenceModel(topics=lda_lsi_topics[:10], texts=train_texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "lsi_coherence_Update = CoherenceModel(topics=lsitopics_update[:10], texts=newdf[\"allWords\"], dictionary=vocab, window_size=10).get_coherence()\n",
    "lda_model_tfidf_coher = CoherenceModel(topics=lda_model_tfidf_topics, texts=newdf[\"allWords\"], dictionary=vocab, window_size=10).get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bar_graph(coherences, indices):\n",
    "    \"\"\"\n",
    "    Function to plot bar graph.\n",
    "    \n",
    "    coherences: list of coherence values\n",
    "    indices: Indices to be used to mark bars. Length of this and coherences should be equal.\n",
    "    \"\"\"\n",
    "    assert len(coherences) == len(indices)\n",
    "    n = len(coherences)\n",
    "    x = np.arange(n)\n",
    "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Coherence Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bar_graph([lsi_coherence, hdp_coherence, lda_coherence,lsi_coherence_Update,lda_model_tfidf_coher],\n",
    "                   ['LSI', 'HDP', 'LDA', \"LSI_U\", \"LDA_Idf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, bow_corpus, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[\"Topic_LSI_Update\"] = newdf[\"allWords\"].apply(getMyTopic, args=[lsimodelUpdate])\n",
    "newdf[\"Prob_LSI_Update\"] = newdf[\"allWords\"].apply(getMyTopic1,args=[lsimodelUpdate])\n",
    "newdf[\"Topic_LSI\"] = newdf[\"allWords\"].apply(getMyTopic, args=[lsimodel])\n",
    "newdf[\"Prob_LSI\"] = newdf[\"allWords\"].apply(getMyTopic1,args=[lsimodel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[newdf['CleanHeadline'].str.contains(\"unfall\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf[newdf['CleanHeadline'].str.contains(\"brand\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "data = newdf[\"allWords\"].apply(getElement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10\n",
    " \n",
    "vectorizer = CountVectorizer(min_df=5, max_df=0.9, \n",
    "                             lowercase=True, \n",
    "                             token_pattern='[a-zA-Z\\-][a-zA-Z\\-]{2,}')\n",
    "data_vectorized = vectorizer.fit_transform(data)\n",
    " \n",
    "# Build a Latent Dirichlet Allocation Model\n",
    "lda_model = LatentDirichletAllocation(n_topics=NUM_TOPICS, max_iter=10, learning_method='online')\n",
    "lda_Z = lda_model.fit_transform(data_vectorized)\n",
    "print(lda_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " \n",
    "# Build a Non-Negative Matrix Factorization Model\n",
    "nmf_model = NMF(n_components=NUM_TOPICS)\n",
    "nmf_Z = nmf_model.fit_transform(data_vectorized)\n",
    "print(nmf_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " \n",
    "# Build a Latent Semantic Indexing Model\n",
    "lsi_model = TruncatedSVD(n_components=NUM_TOPICS)\n",
    "lsi_Z = lsi_model.fit_transform(data_vectorized)\n",
    "print(lsi_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1 =models.TfidfModel(corpus=bow_corpus, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
